{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hilbert-HN/HN_ML_From_Scratch/blob/main/playground_AI/01_AI_on_Cristiano_Ronaldo/MulitPose_MoveNet_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTdsrCNK-KSX"
      },
      "source": [
        "Tutorial: https://www.youtube.com/watch?v=KC7nJtBHBqg \\\n",
        "tensorflow-hub: https://tfhub.dev/ \\\n",
        "tensorflow-hub [movenet/multipose/lightning]: https://tfhub.dev/google/movenet/multipose/lightning/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaAzFSPb914A"
      },
      "source": [
        "# **0. Install and Import Dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyFb9rov_dNu"
      },
      "source": [
        "**use movenet/multipose/lightning from tensorflow-hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oGnw6APp-Hh3"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nOscHEyP-l5f"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kg8_xdswAT4c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5UIsfpnLBa11"
      },
      "outputs": [],
      "source": [
        "# Optional if you are using a GPU\n",
        "# limit the memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfFHr3JbCBKg",
        "outputId": "7414b15e-efa7-4186-9c11-7229a6183804"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpQ2IoSI96e_"
      },
      "source": [
        "# **1. Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bgmxkCc1DNW2"
      },
      "outputs": [],
      "source": [
        "# Refer to \"Usage\" section in documentation in Tensorflow hub\n",
        "# https://tfhub.dev/google/movenet/multipose/lightning/1\n",
        "\n",
        "model = hub.load(\"https://tfhub.dev/google/movenet/multipose/lightning/1\")\n",
        "movenet = model.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA0X9cWx9-hH"
      },
      "source": [
        "# **2. Make Detections**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYi0NsZloHvS"
      },
      "source": [
        "## Drawing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ykc0MOSHlbiC"
      },
      "outputs": [],
      "source": [
        "# Function to loop through each person detected and redner \n",
        "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
        "  for person in keypoints_with_scores:\n",
        "    draw_connections(frame, person, edges, confidence_threshold)\n",
        "    draw_keypoints(frame, person, confidence_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fEo6zxQMnddi"
      },
      "outputs": [],
      "source": [
        "EDGES = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FUGJf8ivleFK"
      },
      "outputs": [],
      "source": [
        "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for kp in shaped:\n",
        "        ky, kx, kp_conf = kp\n",
        "        if kp_conf > confidence_threshold:\n",
        "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0mAEG0MVlgo8"
      },
      "outputs": [],
      "source": [
        "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for edge, color in edges.items():\n",
        "        p1, p2 = edge\n",
        "        y1, x1, c1 = shaped[p1]\n",
        "        y2, x2, c2 = shaped[p2]\n",
        "        \n",
        "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
        "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8xaycZ5K6LY"
      },
      "source": [
        "## For Jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1egJosDTkpLg"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "frame_index = 0\n",
        "\n",
        "cap = cv2.VideoCapture('noval.mp4')\n",
        "# cap = cv2.VideoCapture('C Ronaldo.mp4')\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # Resize image\n",
        "    img = frame.copy()\n",
        "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
        "    input_img = tf.cast(img, dtype=tf.int32)\n",
        "    \n",
        "    # Detection section\n",
        "    results = movenet(input_img)\n",
        "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
        "    \n",
        "    # Render keypoints \n",
        "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
        "\n",
        "    # cv2.imshow('Movenet Multipose', frame)\n",
        "    frames.append(frame)\n",
        "    print(frame_index)\n",
        "    frame_index += 1\n",
        "    if frame_index == 100:\n",
        "      break\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "      break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xf7eTv-gmrEm"
      },
      "outputs": [],
      "source": [
        "for i, frame in enumerate(frames):\n",
        "  print(i)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usZDHjwmJpA7"
      },
      "source": [
        "## For Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MQ0eXEMJ0Da"
      },
      "source": [
        "To allow Webcam / Video analysis work on Colab. \\\n",
        "You will required below codes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syIVkz-7LRS-"
      },
      "source": [
        "### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE7CwWeUIWsF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5xyWMLOJhLi"
      },
      "source": [
        "### Helper Functions - Image / Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCIZHdiCJCe8"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMnzL4VEIKwx"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIMj9DQlKQF5"
      },
      "source": [
        "### Running on Webcam Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "nViZRdJQIsSl",
        "outputId": "237afbca-4450-4c20-c1ab-f1af4101ccdb"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-0088fece098e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-a05efe86d862>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "# cap = cv2.VideoCapture('novak.mp4')\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "\n",
        "    # -----------Add below bbox_array to render something on top of the CAM / video---------------\n",
        "    # Also add bbox_array to your rendering functions\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # -----------input your own code below----------------\n",
        "    ## Resize image\n",
        "    # image size to be in multiple of 32\n",
        "    # close to original aspect ratio\n",
        "    # longer size be 256\n",
        "    img = frame.copy()\n",
        "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192, 256)\n",
        "    input_img = tf.cast(img, dtype=tf.int32)\n",
        "\n",
        "    # Detection section\n",
        "    results = movenet(input_img)\n",
        "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape(6,17,3)\n",
        "\n",
        "    # Render keypoints\n",
        "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3, bbox_array)\n",
        "\n",
        "    # -----------Add below bbox_array to render something on top of the CAM / video---------------\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44UKIY9VSOOE"
      },
      "source": [
        "**The order of the 17 keypoint joints is:** \\\n",
        "[nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]. \\\n",
        "\n",
        "**The remaining 5 elements** \\\n",
        "[ymin, xmin, ymax, xmax, score]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl-hpA-EUNLe"
      },
      "outputs": [],
      "source": [
        "# Function to loop through each person detected and redner \n",
        "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold, bbox_array):\n",
        "  for person in keypoints_with_scores:\n",
        "    draw_connections(frame, person, edges, confidence_threshold, bbox_array)\n",
        "    draw_keypoints(frame, person, confidence_threshold, bbox_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjsxRGPUsIt"
      },
      "source": [
        "# **2a. Debuggig**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RtbvnUKL9Nu"
      },
      "outputs": [],
      "source": [
        "# show the frame captued and convert to right color channel order in openCV\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G85TFLH2Pcyr",
        "outputId": "ccaf295b-df9d-46a2-9eae-0b0fe188fbbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[7.71245599e-01, 7.83745825e-01, 2.89876133e-01],\n",
              "        [6.55809641e-01, 8.59675825e-01, 3.66784483e-01],\n",
              "        [6.68464661e-01, 6.77065611e-01, 5.00870466e-01],\n",
              "        [6.91803873e-01, 9.33493733e-01, 4.12414186e-02],\n",
              "        [7.02996254e-01, 5.59518754e-01, 3.67192566e-01],\n",
              "        [8.77185822e-01, 9.19583797e-01, 2.36720103e-03],\n",
              "        [8.47760737e-01, 4.56126571e-01, 2.19837382e-01],\n",
              "        [7.36677051e-01, 9.60782886e-01, 1.90645624e-02],\n",
              "        [8.70474398e-01, 3.04133087e-01, 5.89331686e-02],\n",
              "        [6.61943138e-01, 8.68139029e-01, 4.11501229e-02],\n",
              "        [7.24192142e-01, 4.76850778e-01, 1.78363994e-02],\n",
              "        [8.58069956e-01, 6.51545644e-01, 1.47443516e-02],\n",
              "        [8.79938781e-01, 4.48165447e-01, 8.78432300e-03],\n",
              "        [7.46429980e-01, 8.90855849e-01, 7.46415171e-04],\n",
              "        [7.75877774e-01, 5.59283614e-01, 7.90146738e-02],\n",
              "        [4.20849174e-01, 6.12614989e-01, 3.95057490e-03],\n",
              "        [4.51202542e-01, 5.33603728e-01, 1.02784941e-02]],\n",
              "\n",
              "       [[7.76329696e-01, 7.84790456e-01, 4.65148568e-01],\n",
              "        [6.58324778e-01, 8.60313416e-01, 1.74429163e-01],\n",
              "        [6.69183791e-01, 6.78526163e-01, 3.67393583e-01],\n",
              "        [7.15983629e-01, 9.64573622e-01, 6.53575659e-02],\n",
              "        [7.02996254e-01, 5.59518754e-01, 3.67192566e-01],\n",
              "        [8.83238256e-01, 9.80277836e-01, 7.48581160e-03],\n",
              "        [8.55532587e-01, 4.25847292e-01, 2.09561050e-01],\n",
              "        [8.91291320e-01, 9.86631274e-01, 9.50589128e-06],\n",
              "        [8.73339295e-01, 3.15715194e-01, 1.79403592e-04],\n",
              "        [8.57252359e-01, 9.33056295e-01, 1.92213506e-02],\n",
              "        [8.19154978e-01, 5.29762387e-01, 2.58800592e-02],\n",
              "        [8.71113181e-01, 8.20841610e-01, 3.44338559e-06],\n",
              "        [8.83187771e-01, 5.05890727e-01, 8.49850679e-08],\n",
              "        [8.46651077e-01, 9.24908042e-01, 3.37901642e-03],\n",
              "        [8.25876951e-01, 5.34882247e-01, 1.80497188e-02],\n",
              "        [6.46160483e-01, 5.87557495e-01, 1.23104546e-03],\n",
              "        [6.55335963e-01, 5.81479907e-01, 1.11854058e-02]],\n",
              "\n",
              "       [[7.71245599e-01, 7.83745825e-01, 2.89876133e-01],\n",
              "        [6.55809641e-01, 8.59675825e-01, 3.66784483e-01],\n",
              "        [6.68464661e-01, 6.77065611e-01, 5.00870466e-01],\n",
              "        [6.84855640e-01, 9.49816883e-01, 1.17312886e-01],\n",
              "        [7.02996254e-01, 5.59518754e-01, 3.67192566e-01],\n",
              "        [8.22523355e-01, 9.82840359e-01, 4.10732301e-03],\n",
              "        [8.45099628e-01, 4.88416851e-01, 8.84850696e-02],\n",
              "        [8.17188263e-01, 9.78818715e-01, 2.93625370e-02],\n",
              "        [8.26618850e-01, 4.95629132e-01, 1.29719265e-02],\n",
              "        [7.49345183e-01, 9.74044085e-01, 3.09604239e-02],\n",
              "        [6.72160089e-01, 5.45094132e-01, 2.31793560e-02],\n",
              "        [7.84288526e-01, 9.25801456e-01, 8.89337528e-03],\n",
              "        [8.09754074e-01, 5.79912245e-01, 5.41083701e-03],\n",
              "        [6.17080748e-01, 9.70801890e-01, 2.45773699e-03],\n",
              "        [7.65081584e-01, 6.39892042e-01, 1.22297324e-01],\n",
              "        [3.48260581e-01, 8.71986508e-01, 5.09792892e-03],\n",
              "        [3.77111852e-01, 6.66554630e-01, 8.24915711e-03]],\n",
              "\n",
              "       [[4.18461949e-01, 8.05736985e-03, 8.75646435e-03],\n",
              "        [3.79849881e-01, 9.01045091e-03, 9.43708047e-03],\n",
              "        [3.80945563e-01, 6.60574064e-03, 8.14738963e-03],\n",
              "        [3.87385398e-01, 1.20474612e-02, 6.07547257e-03],\n",
              "        [3.89489293e-01, 7.16062356e-03, 1.44987283e-02],\n",
              "        [4.77363408e-01, 2.32477672e-02, 1.08026788e-02],\n",
              "        [4.75968033e-01, 3.05750128e-02, 1.51583105e-02],\n",
              "        [5.05273223e-01, 7.08812252e-02, 1.42577998e-02],\n",
              "        [4.87047821e-01, 3.51088867e-02, 8.25252105e-03],\n",
              "        [4.83400971e-01, 2.38136314e-02, 1.10995639e-02],\n",
              "        [5.02011299e-01, 1.01733483e-01, 1.16514554e-02],\n",
              "        [5.87555408e-01, 7.27399960e-02, 1.13348449e-02],\n",
              "        [5.83546519e-01, 3.06116119e-02, 8.64211749e-03],\n",
              "        [6.23884857e-01, 1.05464540e-01, 1.56473666e-02],\n",
              "        [6.36249423e-01, 7.92831182e-02, 1.14306211e-02],\n",
              "        [6.81276441e-01, 1.02345891e-01, 8.38162284e-03],\n",
              "        [6.64079607e-01, 8.61632302e-02, 6.28259685e-03]],\n",
              "\n",
              "       [[6.06580257e-01, 2.00144589e-01, 8.69713444e-03],\n",
              "        [5.98386526e-01, 2.02221513e-01, 1.27021689e-02],\n",
              "        [5.99422216e-01, 1.94625765e-01, 1.14079993e-02],\n",
              "        [6.02753460e-01, 2.08082080e-01, 7.05751125e-03],\n",
              "        [6.03927195e-01, 1.95141315e-01, 1.37418797e-02],\n",
              "        [6.52343452e-01, 2.21123174e-01, 6.25750050e-03],\n",
              "        [6.33726835e-01, 1.85977906e-01, 9.02506057e-03],\n",
              "        [7.83293247e-01, 2.77946174e-01, 1.26996711e-02],\n",
              "        [7.19766974e-01, 1.34751573e-01, 1.33107137e-02],\n",
              "        [7.35789061e-01, 2.18152851e-01, 2.17539668e-02],\n",
              "        [7.20717371e-01, 1.88139334e-01, 1.13374768e-02],\n",
              "        [8.73250842e-01, 2.52837718e-01, 2.51133218e-02],\n",
              "        [8.54631305e-01, 1.78972006e-01, 2.23898198e-02],\n",
              "        [8.59579265e-01, 2.83944249e-01, 2.70768609e-02],\n",
              "        [8.52675080e-01, 1.45254582e-01, 2.34226808e-02],\n",
              "        [8.59818637e-01, 2.70704687e-01, 1.65290814e-02],\n",
              "        [8.47712576e-01, 1.42202243e-01, 1.55550186e-02]],\n",
              "\n",
              "       [[7.16878831e-01, 8.09917808e-01, 5.81890251e-03],\n",
              "        [6.55809641e-01, 8.59675825e-01, 3.66784483e-01],\n",
              "        [6.37019157e-01, 7.86187530e-01, 1.05608243e-03],\n",
              "        [6.64824128e-01, 9.62825716e-01, 1.15551665e-01],\n",
              "        [6.49553955e-01, 8.97035062e-01, 2.71908799e-03],\n",
              "        [6.50598705e-01, 9.54357088e-01, 3.36621911e-03],\n",
              "        [6.48790061e-01, 9.68979776e-01, 5.25100040e-04],\n",
              "        [7.55811691e-01, 9.81379986e-01, 4.41684127e-02],\n",
              "        [6.24422312e-01, 8.67860556e-01, 6.74941402e-04],\n",
              "        [6.83030248e-01, 8.95333290e-01, 5.24890311e-02],\n",
              "        [6.10133350e-01, 8.05977106e-01, 4.02059732e-03],\n",
              "        [6.50207698e-01, 9.76604164e-01, 9.98142362e-03],\n",
              "        [6.40720904e-01, 9.51872408e-01, 9.82275326e-03],\n",
              "        [8.02390277e-01, 9.47542012e-01, 7.12899351e-03],\n",
              "        [7.57378578e-01, 8.55003655e-01, 3.98261007e-03],\n",
              "        [6.30154490e-01, 9.84636188e-01, 1.22353202e-02],\n",
              "        [6.07998252e-01, 9.31938827e-01, 1.05353410e-03]]], dtype=float32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.keys()\n",
        "# key: output_0\n",
        "# shape=(1, 6, 56)\n",
        "# 6 people, [17 keypoints (each keypoint consist on x,y,score) = 51 + 5 bounding box] = 56\n",
        "# get the first 51 keypoints\n",
        "# reshape so the matrix show 6 people, with 17 keypoints with 3 values\n",
        "results['output_0'].numpy()[:,:,:51].reshape((6,17,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsM06QTvSmY8",
        "outputId": "10697827-a937-4349-a946-541b3335b525"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[7.1295965e-01, 7.9407114e-01, 4.6980116e-01],\n",
              "       [5.9965909e-01, 8.5591871e-01, 5.4849637e-01],\n",
              "       [6.0389894e-01, 6.7563164e-01, 5.5109423e-01],\n",
              "       [6.4719439e-01, 8.7866950e-01, 4.0800408e-02],\n",
              "       [6.4391869e-01, 5.3318614e-01, 4.3820333e-01],\n",
              "       [8.7057215e-01, 8.7538195e-01, 2.7269499e-02],\n",
              "       [8.6764216e-01, 3.2354763e-01, 3.5445666e-01],\n",
              "       [8.3974141e-01, 8.9413124e-01, 1.2316870e-02],\n",
              "       [8.7059027e-01, 2.9584390e-01, 1.7361097e-02],\n",
              "       [6.6337019e-01, 8.8659084e-01, 9.8222159e-02],\n",
              "       [7.4100393e-01, 5.3474063e-01, 2.1906585e-02],\n",
              "       [8.7246090e-01, 6.2498808e-01, 3.7731538e-03],\n",
              "       [8.8461286e-01, 4.2799258e-01, 2.4132668e-03],\n",
              "       [6.7941916e-01, 9.1377860e-01, 6.4175618e-03],\n",
              "       [7.4849123e-01, 6.0424829e-01, 8.7541990e-02],\n",
              "       [3.2529619e-01, 7.8545558e-01, 2.6253273e-03],\n",
              "       [3.4925783e-01, 6.8339717e-01, 6.3009548e-04]], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# keypoint of first person\n",
        "keypoints_with_scores[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyeWaJWJZP7Q",
        "outputId": "af8ef9f7-8dde-4ff2-f62b-1679f5414a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 640, 3)\n",
            "0.75\n",
            "192.0\n",
            "6.0\n"
          ]
        }
      ],
      "source": [
        "# calculate the to reshape\n",
        "print(frame.shape)\n",
        "print(480/640)\n",
        "print(256*0.75)\n",
        "print(192/32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "splz0u6sZahK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caa5Xu4N-As_"
      },
      "source": [
        "# **3. Draw Keypoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQDstTNPG8sG"
      },
      "outputs": [],
      "source": [
        "def draw_keypoints(frame, keypoints, confidence_threshold, bbox_array):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for kp in shaped:\n",
        "        ky, kx, kp_conf = kp\n",
        "        if kp_conf > confidence_threshold:\n",
        "            # cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
        "            bbox_array = cv2.circle(bbox_array, (int(kx), int(ky)), 4, (0,255,0), -1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52_UjGDr-Ek_"
      },
      "source": [
        "# **4. Draw Edges**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7XXcReXLIH0"
      },
      "outputs": [],
      "source": [
        "EDGES = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE4IWOUPLm5K"
      },
      "outputs": [],
      "source": [
        "def draw_connections(frame, keypoints, edges, confidence_threshold, bbox_array):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for edge, color in edges.items():\n",
        "        p1, p2 = edge\n",
        "        y1, x1, c1 = shaped[p1]\n",
        "        y2, x2, c2 = shaped[p2]\n",
        "        \n",
        "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
        "            #cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
        "            bbox_array = cv2.line(bbox_array, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAJKfsupTZga"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DaAzFSPb914A",
        "WpQ2IoSI96e_",
        "syIVkz-7LRS-",
        "H5xyWMLOJhLi",
        "lEjsxRGPUsIt"
      ],
      "name": "MulitPose MoveNet Tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCs2CDlzv/ZVmNqOaFX8vD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}